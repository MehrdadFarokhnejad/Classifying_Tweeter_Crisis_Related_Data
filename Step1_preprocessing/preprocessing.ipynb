{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>other_useful_information</td>\n",
       "      <td>RT @nicoleewayne: Tennessee USA Knoxville http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>infrastructure_and_utilities_damage</td>\n",
       "      <td>RT @SFGate: We're updating this interactive ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>injured_or_dead_people</td>\n",
       "      <td>RT @YourAnonNews: Strong 6.1 Earthquake Rocks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>infrastructure_and_utilities_damage</td>\n",
       "      <td>RT @heyyouapp: Wisconsin USA Madison http://t....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>other_useful_information</td>\n",
       "      <td>RT @scullather: \"@infodude: amazing use of #Bi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 label  \\\n",
       "0             other_useful_information   \n",
       "1  infrastructure_and_utilities_damage   \n",
       "2               injured_or_dead_people   \n",
       "3  infrastructure_and_utilities_damage   \n",
       "4             other_useful_information   \n",
       "\n",
       "                                          tweet_text  \n",
       "0  RT @nicoleewayne: Tennessee USA Knoxville http...  \n",
       "1  RT @SFGate: We're updating this interactive ma...  \n",
       "2  RT @YourAnonNews: Strong 6.1 Earthquake Rocks ...  \n",
       "3  RT @heyyouapp: Wisconsin USA Madison http://t....  \n",
       "4  RT @scullather: \"@infodude: amazing use of #Bi...  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "import re\n",
    "\n",
    "# Download and Load label data from https://crisisnlp.qcri.org/\n",
    "dataset_name = '2014_california_eq_raw.csv'\n",
    "data= pd.read_csv(r'Raw_data/%s'%dataset_name, encoding='latin-1')\n",
    "\n",
    "# remove additoonal columns\n",
    "data.drop('_golden', axis =1 , inplace = True)\n",
    "data.drop('_unit_state', axis =1 , inplace = True)\n",
    "data.drop('_trusted_judgments', axis =1 , inplace = True)\n",
    "data.drop('_last_judgment_at', axis =1 , inplace = True)\n",
    "data.drop('choose_one_category_gold', axis =1 , inplace = True)\n",
    "data.drop('choose_one_category:confidence', axis =1 , inplace = True)\n",
    "data.drop('_unit_id', axis =1 , inplace = True)\n",
    "data.drop('tweet_id', axis =1 , inplace = True)\n",
    "# rename comumns\n",
    "data = data.rename (columns= {'choose_one_category':'label','tweet_text':'tweet_text'})\n",
    "data_top = data.head(5)\n",
    "data_top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "dataset = []\n",
    "for i in range(0,len(data)):\n",
    "        string = str (data['tweet_text'][i])\n",
    "        x = re.sub(\"\\[\\'text:\\\"RT @.*?: \", \"\", string)\n",
    "        x = re.sub(\"http.*\", \"\",x)\n",
    "        x = re.sub(\"\\[\\'text:\", \"\", x)\n",
    "        x = re.sub(\"\\].*\", \"\", x)\n",
    "        x = re.sub(\"\\\\\\\\\", \"\", x)\n",
    "        x = re.sub(\"\\\\'\", \"\", x)\n",
    "        x = re.sub(\"RT\", \"\", x)\n",
    "        x= re.sub(\"http\", \"\", x)\n",
    "        x = re.sub(\":\", \"\", x)\n",
    "        x = re.sub(\"@\", \"\", x)\n",
    "        x = re.sub(\"#\", \"\", x)\n",
    "        x = re.sub(\"//\", \"\", x)\n",
    "        data['tweet_text'][i] = ''\n",
    "        data['tweet_text'][i] =  x  \n",
    "Text_label_data = data\n",
    "Text_label_data.to_csv('pre_process_data/Text_label_'+'%s'%dataset_name+'.csv' , encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>other_useful_information</td>\n",
       "      <td>nicoleewayne Tennessee USA Knoxville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>infrastructure_and_utilities_damage</td>\n",
       "      <td>SFGate Were updating this interactive map of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>injured_or_dead_people</td>\n",
       "      <td>YourAnonNews Strong 6.1 Earthquake Rocks San ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>infrastructure_and_utilities_damage</td>\n",
       "      <td>heyyouapp Wisconsin USA Madison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>other_useful_information</td>\n",
       "      <td>scullather \"infodude amazing use of BigData f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 label  \\\n",
       "0             other_useful_information   \n",
       "1  infrastructure_and_utilities_damage   \n",
       "2               injured_or_dead_people   \n",
       "3  infrastructure_and_utilities_damage   \n",
       "4             other_useful_information   \n",
       "\n",
       "                                          tweet_text  \n",
       "0              nicoleewayne Tennessee USA Knoxville   \n",
       "1   SFGate Were updating this interactive map of ...  \n",
       "2   YourAnonNews Strong 6.1 Earthquake Rocks San ...  \n",
       "3                   heyyouapp Wisconsin USA Madison   \n",
       "4   scullather \"infodude amazing use of BigData f...  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_top = data.head(5)\n",
    "data_top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noramlization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Step - 1a : Remove blank rows if any.\n",
    "data['tweet_text'].dropna(inplace=True)\n",
    "\n",
    "# Step - 1b : Change all the text to lower case. This is required as python interprets 'dog' and 'DOG' differently\n",
    "data['tweet_text'] = [entry.lower() for entry in data['tweet_text']]\n",
    "\n",
    "# Step - 1c : Tokenization : In this each entry in the corpus will be broken into set of words\n",
    "data['tweet_text']= [word_tokenize(entry) for entry in data['tweet_text']]\n",
    "\n",
    "# Step - 1d : Remove Stop words, Non-Numeric and perfom Word Stemming/Lemmenting.\n",
    "\n",
    "# WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. By default it is set to Noun\n",
    "tag_map = defaultdict(lambda: wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "\n",
    "\n",
    "for index,entry in enumerate(data['tweet_text']):\n",
    "    # Declaring Empty List to store the words that follow the rules for this step\n",
    "    Final_words = []\n",
    "    # Initializing WordNetLemmatizer()\n",
    "    word_Lemmatized = WordNetLemmatizer()\n",
    "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
    "    for word, tag in pos_tag(entry):\n",
    "        # Below condition is to check for Stop words and consider only alphabets\n",
    "        if word not in stopwords.words('english') and word.isalpha():\n",
    "            word_Final = word_Lemmatized.lemmatize(word, tag_map[tag[0]])\n",
    "            word_Final = re.sub(\"rt\", \"\", word_Final)\n",
    "            word_Final = re.sub(\"http\", \"\", word_Final)\n",
    "            word_Final = re.sub(\":\", \"\", word_Final)\n",
    "            word_Final = re.sub(\"@\", \"\", word_Final)\n",
    "            word_Final = re.sub(\"#\", \"\", word_Final)\n",
    "            word_Final = re.sub(\"//\", \"\", word_Final)\n",
    "            Final_words.append(word_Final)\n",
    "    # The final processed set of words for each iteration will be stored in 'text_final'\n",
    "    data.loc[index, 'text_final'] = str(Final_words)\n",
    "    data['text_final'].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>text_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>other_useful_information</td>\n",
       "      <td>[nicoleewayne, tennessee, usa, knoxville]</td>\n",
       "      <td>['nicoleewayne', 'tennessee', 'usa', 'knoxville']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>infrastructure_and_utilities_damage</td>\n",
       "      <td>[sfgate, were, updating, this, interactive, ma...</td>\n",
       "      <td>['sfgate', 'update', 'interactive', 'map', 're...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>injured_or_dead_people</td>\n",
       "      <td>[youranonnews, strong, 6.1, earthquake, rocks,...</td>\n",
       "      <td>['youranonnews', 'strong', 'eahquake', 'rock',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>infrastructure_and_utilities_damage</td>\n",
       "      <td>[heyyouapp, wisconsin, usa, madison]</td>\n",
       "      <td>['heyyouapp', 'wisconsin', 'usa', 'madison']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>other_useful_information</td>\n",
       "      <td>[scullather, ``, infodude, amazing, use, of, b...</td>\n",
       "      <td>['scullather', 'infodude', 'amazing', 'use', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 label  \\\n",
       "0             other_useful_information   \n",
       "1  infrastructure_and_utilities_damage   \n",
       "2               injured_or_dead_people   \n",
       "3  infrastructure_and_utilities_damage   \n",
       "4             other_useful_information   \n",
       "\n",
       "                                          tweet_text  \\\n",
       "0          [nicoleewayne, tennessee, usa, knoxville]   \n",
       "1  [sfgate, were, updating, this, interactive, ma...   \n",
       "2  [youranonnews, strong, 6.1, earthquake, rocks,...   \n",
       "3               [heyyouapp, wisconsin, usa, madison]   \n",
       "4  [scullather, ``, infodude, amazing, use, of, b...   \n",
       "\n",
       "                                          text_final  \n",
       "0  ['nicoleewayne', 'tennessee', 'usa', 'knoxville']  \n",
       "1  ['sfgate', 'update', 'interactive', 'map', 're...  \n",
       "2  ['youranonnews', 'strong', 'eahquake', 'rock',...  \n",
       "3       ['heyyouapp', 'wisconsin', 'usa', 'madison']  \n",
       "4  ['scullather', 'infodude', 'amazing', 'use', '...  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_top = data.head(5)\n",
    "data_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
